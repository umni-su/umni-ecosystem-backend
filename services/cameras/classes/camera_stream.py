import datetime
import os
import time
from typing import TYPE_CHECKING, Optional, Union

import av
import cv2
import imutils
import numpy as np
from av import VideoFrame
from pydantic import BaseModel

import classes.crypto.crypto as crypto
from classes.logger import Logger
from classes.storages.camera_storage import CameraStorage
from classes.storages.filesystem import Filesystem
from classes.thread.Daemon import Daemon
from entities.camera import CameraEntity

from entities.enums.camera_record_type_enum import CameraRecordTypeEnum
from repositories.camera_events_repository import CameraEventsRepository
from services.cameras.classes.camera_notifier import CameraNotifier
from services.cameras.classes.roi_tracker import ROIDetectionEvent
from services.cameras.classes.roi_tracker import ROITracker

if TYPE_CHECKING:
    from entities.camera_event import CameraEventEntity
    from services.cameras.classes.roi_tracker import ROIRecordEvent


class ScreenshotResultModel(BaseModel):
    success: bool = False
    directory: str
    filename: str


class CameraStream:
    def __init__(self, camera: CameraEntity):
        self.id: int = 0
        self.video_pts = 0
        self.audio_pts = 0
        self.tracker: Optional[ROITracker] = None
        self.opened: bool = True
        self.camera: Optional[CameraEntity] = None
        self.link: Optional[str] = None

        # Video processing settings
        self.frames_skip: int = 20
        self.detection_size: int = 5000
        self.detection_persistent: int = 100
        self.silence_timer: float = 0
        self.silence_pause: int = 10

        # Frame processing
        self.font = cv2.FONT_HERSHEY_SIMPLEX
        self.delay_counter = 0
        self.movement_persistent_counter = 0
        self.first_frame: Optional[np.ndarray] = None
        self.next_frame: Optional[np.ndarray] = None
        self.fps: int = 10

        # Timing
        self.time_part_start: float = 0
        self.time_prev: float = 0
        self.time_elapsed: float = 0

        # Video frames
        self.original: Optional[Union[np.ndarray | cv2.Mat]] = None
        self.resized: Optional[Union[np.ndarray | cv2.Mat]] = None

        # Threading
        self.daemon: Optional[Daemon] = None

        # Motion detection flags
        self.transient_movement_flag: bool = False
        self.movement_persistent_flag: bool = False
        self.movement_detected: bool = False

        # Storage paths
        self.path: Optional[str] = None
        self.screen_interval: int = 30
        self.screen_timer: float = 0

        # PyAV containers
        self.input_container: Optional[Union[av.container.InputContainer | av.Stream]] = None
        self.output_container: Optional[av.container.OutputContainer] = None
        self.output_stream: Optional[av.Stream] = None
        self.write: bool = False

        # Error handling
        self.capture_error: Optional[bool] = None
        self.output_file: Optional[str] = None
        self.need_skip: bool = False
        self.need_restart: bool = False

        # Heartbeat
        self.last_frame_time = 0  # –í—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ –∫–∞–¥—Ä–∞
        self.heartbeat_timeout = 10  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –±–µ–∑ –∫–∞–¥—Ä–æ–≤ (—Å–µ–∫)
        self.heartbeat_check_interval = 5  # –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏ (—Å–µ–∫)
        self.last_heartbeat_check = 0
        self.restart_delay = 3  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ (—Å–µ–∫)
        self.last_restart_time = 0

        # For permanent events
        self.permanent_event: Optional["CameraEventEntity"] = None

        self.set_camera(camera=camera)
        dmn = 'was_none'

        if isinstance(self.daemon, Daemon):
            if not self.daemon.thread.is_alive():
                self.daemon.thread = None
                self.daemon = None
                dmn = 'was_dead'

        if self.daemon is None:
            self.daemon = Daemon(self.loop_frames)
            Logger.debug(f"üëª [{self.camera.name}] Daemon was created, reason={dmn}")

    # Event handlers (unchanged)
    def handle_motion_start(self, event: "ROIDetectionEvent"):
        CameraNotifier.handle_motion_start(event, self)

    def handle_motion_end(self, event: "ROIDetectionEvent"):
        CameraNotifier.handle_motion_end(event, self)

    def handle_recording_start(self, event: "ROIRecordEvent"):
        self.write = True
        CameraNotifier.handle_recording_start(event, self)

    def handle_recording_end(self, event: "ROIRecordEvent"):
        CameraNotifier.handle_recording_end(event, self)

    def prepare_link(self, camera: CameraEntity, secondary: bool = False):
        userinfo = ''
        if camera.username is not None and camera.password is not None:
            password = crypto.Crypto.decrypt(camera.password)
            userinfo = f'{camera.username}:{password}@'
        stream = camera.primary
        if secondary:
            stream = camera.secondary
        port = 554
        if camera.port is not None:
            port = camera.port
        proto = ''
        if camera.protocol is not None:
            proto = camera.protocol
        return f'{proto.lower()}://{userinfo}{camera.ip}:{port}/{stream}'

    def set_camera(self, camera: CameraEntity):
        self.need_skip = True

        if isinstance(self.camera, CameraEntity) and camera != self.camera:
            self.need_restart = True
            time.sleep(2)
            Logger.warn(f'{self.camera.name} url was changed! Capture should be reload')

        self.camera = camera
        self.id = self.camera.id
        self.link = self.prepare_link(self.camera)
        self.path = os.path.join(self.camera.storage.path, str(self.camera.id))

        if self.camera.record_mode != camera.record_mode:
            self.destroy_output_container()
            self.time_part_start = 0

        if isinstance(self.tracker, ROITracker):
            self.tracker.update_all_rois(self.camera.areas)

        self.need_skip = False

    def date_filename(self):
        return datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S-%f')

    def take_screenshot(self, path: str, prefix: str | None = None, frame: np.ndarray | None = None):
        filename = '.'.join([self.date_filename(), 'jpg'])
        if prefix is not None:
            filename = '.'.join([prefix, filename])

        if not Filesystem.exists(path):
            Filesystem.mkdir(path_or_filename=path, recursive=True)

        full_filename = os.path.join(path, filename)
        _frame = self.original if frame is None else frame
        res = cv2.imwrite(filename=full_filename, img=_frame)

        return ScreenshotResultModel(
            success=res,
            directory=path,
            filename=filename,
        )

    def _create_input_container(self):
        options = {
            'rtsp_transport': 'tcp',
            'stimeout': '5000000',  # 5 seconds timeout
            'max_delay': '500000',  # Max packet delay
        }

        try:
            self.input_container = av.open(self.link, options=options, timeout=10)
            self.capture_error = False
            Logger.debug(f"üéâ [{self.camera.name}] Start capture on link {self.link}")
        except Exception as e:
            self.capture_error = True
            Logger.debug(f"‚ö†Ô∏è [{self.camera.name}] Failed to open stream: {e}")
            time.sleep(3)
            self._create_input_container()

    def create_input_container(self):
        if self.input_container is None:
            self._create_input_container()

    def stop_input_container(self):
        if self.input_container is not None:
            self.input_container.close()
            self.input_container = None

    def is_record_permanent(self):
        return self.is_video_mode() or self.is_screenshots_mode()

    def is_screenshots_mode(self):
        return self.camera.record_mode == CameraRecordTypeEnum.SCREENSHOTS

    def is_video_mode(self):
        return self.camera.record_mode == CameraRecordTypeEnum.VIDEO

    def is_video_detection_mode(self):
        return self.camera.record_mode == CameraRecordTypeEnum.DETECTION_VIDEO

    def is_screenshot_detection_mode(self):
        return self.camera.record_mode == CameraRecordTypeEnum.DETECTION_SCREENSHOTS

    def is_detection_mode(self):
        return self.is_screenshot_detection_mode() or self.is_video_detection_mode()

    def stop_write_video(self):
        self.write = False

    def write_frame_safe(self, frame: VideoFrame):
        if self.output_container is None or frame is None:
            return False

        try:
            # Convert numpy array to PyAV frame
            av_frame = frame

            # Ensure the frame has the same format as the stream
            if self.output_stream is not None:
                av_frame = av_frame.reformat(
                    width=self.output_stream.width,
                    height=self.output_stream.height,
                    format=self.output_stream.format
                )

                # Set the PTS (Presentation Time Stamp)
                if not hasattr(self, 'video_pts'):
                    self.video_pts = 0

                # Calculate PTS increment based on time_base and frame rate
                av_frame.pts = self.video_pts
                input_video_stream = self.input_container.streams.video[0]
                fps = input_video_stream.average_rate
                pts_increment = int(self.output_stream.time_base.denominator / fps)
                self.video_pts += pts_increment

                # Encode and write the frame
                for packet in self.output_stream.encode(av_frame):
                    self.output_container.mux(packet)

            return True

        except EOFError as e:
            self.destroy_output_container()
        except Exception as e:
            Logger.err(f"[{self.camera.name}] PyAV Writer Error: {e}")
            self.destroy_output_container()
            return False

    def destroy_output_container(self):
        if self.output_container is not None:
            # Flush any remaining packets
            if self.output_stream is not None:
                for packet in self.output_stream.encode():
                    self.output_container.mux(packet)

            # –¢–∞–∫–∂–µ —Ñ–ª–∞—à–∏–º –∞—É–¥–∏–æ–ø–∞–∫–µ—Ç—ã, –µ—Å–ª–∏ –µ—Å—Ç—å –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫
            if hasattr(self, 'audio_output_stream') and self.audio_output_stream is not None:
                for packet in self.audio_output_stream.encode():
                    self.output_container.mux(packet)

            self.output_container.close()
            Logger.debug(f"üî≥Ô∏è [{self.camera.name}] Output container stopped: {self.output_file}")

            # –ï—Å–ª–∏ —É –∫–∞–º–µ—Ä—ã —Ä–µ–∂–∏–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–≥–æ –≤–∏–¥–µ–æ –∏–ª–∏ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤,
            # –Ω—É–∂–Ω–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å –∑–∞–ø–∏—Å—å, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å –∏ –æ–±–Ω–æ–≤–∏—Ç—å —Å–æ–±—ã—Ç–∏–µ –∏ –∑–∞–ø–∏—Å—å –≤ –ë–î
            if self.is_record_permanent() and self.permanent_event is not None:
                CameraEventsRepository.close_permanent_event(
                    event=self.permanent_event
                )
                Logger.debug(f'üé¨ [{self.camera.name}] Permanent event end: #ID{self.permanent_event.id}]')
                self.permanent_event = None
            self.output_container = None
            self.output_stream = None
            self.audio_output_stream = None  # –î–æ–±–∞–≤–ª–µ–Ω–æ
            self.output_file = None
            self.time_part_start = 0

    def create_output_container(self, path: str):
        self.video_pts = 0
        self.audio_pts = 0
        if not Filesystem.exists(path):
            Filesystem.mkdir(path, recursive=True)

        filename = f"{self.date_filename()}.mp4"
        full_path = os.path.join(path, filename)

        try:
            # Create output container
            self.output_container = av.open(full_path, mode='w')

            # Get frame info from input or use defaults
            if self.input_container is not None and len(self.input_container.streams.video) > 0:
                input_video_stream = self.input_container.streams.video[0]
                width = input_video_stream.width
                height = input_video_stream.height
                fps = input_video_stream.average_rate
                codec_name = 'h264'

                # Add video stream to container
                self.output_stream = self.output_container.add_stream(codec_name, rate=fps)
                self.output_stream.width = width
                self.output_stream.height = height
                self.output_stream.pix_fmt = 'yuv420p'
                self.output_stream.time_base = input_video_stream.time_base

                # Add audio stream if exists
                if len(self.input_container.streams.audio) > 0:
                    input_audio_stream = self.input_container.streams.audio[0]
                    in_audio_ctx = input_audio_stream.codec_context
                    self.audio_output_stream = self.output_container.add_stream(
                        'aac',
                        rate=in_audio_ctx.sample_rate,
                        layout=in_audio_ctx.layout.name,
                    )
                    self.audio_output_stream.time_base = input_audio_stream.time_base
            else:
                # Fallback values if no input stream
                width, height = 640, 480
                fps = 25
                codec_name = 'h264'
                self.output_stream = self.output_container.add_stream(codec_name, rate=fps)
                self.output_stream.width = width
                self.output_stream.height = height
                self.output_stream.pix_fmt = 'yuv420p'

            self.output_file = full_path
            Logger.debug(f"[{self.camera.name}] Output container started: {full_path}")
            return True

        except Exception as e:
            Logger.err(f"[{self.camera.name}] Failed to initialize output container: {e}")
            self.output_container = None
            self.output_stream = None
            self.audio_output_stream = None
            return False

    def is_stream_alive(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∞–∫—Ç–∏–≤–µ–Ω –ª–∏ –ø–æ—Ç–æ–∫, –≤–∫–ª—é—á–∞—è –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –∑–∞–≤–∏—Å–∞–Ω–∏–µ"""
        if not self.is_opened():
            return False

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–≤–∏—Å–∞–Ω–∏–µ (–Ω–µ—Ç –Ω–æ–≤—ã—Ö –∫–∞–¥—Ä–æ–≤)
        current_time = time.time()
        if current_time - self.last_frame_time > self.heartbeat_timeout:
            Logger.warn(f"‚ö†Ô∏è [{self.camera.name}] Stream frozen - no frames for {self.heartbeat_timeout} sec")
            return False

        try:
            # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            if hasattr(self.input_container, 'is_alive'):
                return self.input_container.is_alive()
            return True
        except (av.error.FFmpegError, EOFError, OSError):
            return False

    def check_heartbeat(self):
        """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ—Ç–æ–∫–∞"""
        current_time = time.time()
        if current_time - self.last_heartbeat_check > self.heartbeat_check_interval:
            self.last_heartbeat_check = current_time
            if not self.is_stream_alive():
                Logger.warn(f"‚ù§Ô∏èü©π [{self.camera.name}] Heartbeat check failed - restarting stream")
                self.need_restart = True

    def is_opened(self):
        return isinstance(self.input_container, av.container.InputContainer)

    def loop_frames(self):
        first_run: bool = True
        need_create_input = False

        if self.input_container is None:
            need_create_input = True

        if need_create_input:
            self.create_input_container()
            Logger.debug(f'[{self.camera.name}] Create input container {self.is_opened()}')

        self.tracker = ROITracker(camera=self.camera)
        self.tracker.set_callbacks(
            motion_start=self.handle_motion_start,
            motion_end=self.handle_motion_end,
            recording_start=self.handle_recording_start,
            recording_end=self.handle_recording_end
        )

        # Initialize PTS counters
        self.video_pts = 0
        self.audio_pts = 0

        while self.camera.active or self.opened:
            try:
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ heartbeat
                self.check_heartbeat()

                if self.need_skip:
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
                current_time = time.time()

                if self.need_restart and (current_time - self.last_restart_time) > self.restart_delay:
                    self._perform_restart()
                    continue

                if self.input_container is None:
                    self.create_input_container()
                    continue

                # –ß–∏—Ç–∞–µ–º –ø–∞–∫–µ—Ç—ã –≤–º–µ—Å—Ç–æ —Ñ—Ä–µ–π–º–æ–≤ –¥–ª—è –ª—É—á—à–µ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                for packet in self.input_container.demux():
                    self.check_heartbeat()  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏
                    if not self.camera.active and not self.opened:
                        break

                    if not self.camera.active and not self.opened:
                        break

                    if self.need_skip or self.need_restart:
                        break

                    # –î–µ–º—É–ª—å—Ç–∏–ø–ª–µ–∫—Å–∏—Ä—É–µ–º –ø–∞–∫–µ—Ç—ã –≤ —Ñ—Ä–µ–π–º—ã
                    for frame in packet.decode():
                        self.last_frame_time = time.time()  # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞
                        if isinstance(frame, av.AudioFrame) and hasattr(self,
                                                                        'audio_output_stream') and self.audio_output_stream is not None:
                            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ—Ñ—Ä–µ–π–º–æ–≤
                            if self.output_container is not None and self.write:
                                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º PTS –¥–ª—è –∞—É–¥–∏–æ
                                if not hasattr(self, 'audio_pts'):
                                    self.audio_pts = 0
                                frame.pts = self.audio_pts
                                self.audio_pts += frame.samples

                                # –ö–æ–¥–∏—Ä—É–µ–º –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –∞—É–¥–∏–æ—Ñ—Ä–µ–π–º
                                for packet in self.audio_output_stream.encode(frame):
                                    if self.audio_output_stream is not None:
                                        self.output_container.mux(packet)
                                    else:
                                        break
                            else:
                                self.destroy_output_container()
                            continue

                        if isinstance(frame, av.VideoFrame):
                            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ—Ñ—Ä–µ–π–º–æ–≤
                            self.original = frame.to_ndarray(format='bgr24')
                            self.resized = imutils.resize(self.original, width=640)

                            # Start permanent record or permanent screenshots
                            if self.is_record_permanent() and self.time_part_start == 0:
                                self.time_part_start = time.time()

                                if self.is_screenshots_mode():
                                    res = CameraStorage.take_screenshot(self.camera, self.original)
                                    Logger.debug(
                                        f"[Camera {self.camera.name}] Take screenshot: success={res.success}, fn={res.filename}, dir={res.directory}]")
                                elif self.is_video_mode() and (self.output_container is None):
                                    self.create_output_container(CameraStorage.video_path(self.camera))
                                    self.write = True
                                    # Create event
                                    self.permanent_event = CameraEventsRepository.add_permanent_event(
                                        camera=self.camera,
                                        frame=self.original,
                                        record_path=self.output_file
                                    )
                                    Logger.debug(
                                        f'üé¨ [{self.camera.name}] Permanent event start: #ID{self.permanent_event.id}]')

                                Logger.debug(
                                    f'üìΩ [{self.camera.name}] with permanent record mode: {self.camera.record_mode}')

                            # Take cover
                            now = time.time()
                            elapsed = now - self.screen_timer

                            if elapsed > self.screen_interval:
                                CameraStorage.upload_cover(self.camera, self.original)
                                self.screen_timer = now

                            # Write frames to output container if needed
                            if self.output_container is not None and self.write:
                                self.write_frame_safe(frame)
                            else:
                                self.destroy_output_container()

                            pause = time.time() - self.silence_timer

                            if self.is_detection_mode() and (pause > self.silence_pause or first_run is True):
                                frame_copy = self.resized.copy()
                                changes = self.tracker.detect_changes(frame_copy, self.original)
                                __frame = self.tracker.draw_rois(frame_copy, changes)

                            elif self.is_record_permanent():
                                record_part_diff = time.time() - self.time_part_start
                                if record_part_diff > self.camera.record_duration * 60:
                                    self.destroy_output_container()
                                    Logger.debug(f'Camera {self.camera.name} end record video part')

                            first_run = False

            except EOFError as e:
                Logger.warn(f"‚ö†Ô∏è [{self.camera.name}] EOF reached, stream may be disconnected: {e}")
                self.need_restart = True
                time.sleep(1)  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–±–æ–ª—å—à—É—é –ø–∞—É–∑—É –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
                pass
            except av.error.FFmpegError as e:
                Logger.err(f"‚ö†Ô∏è [{self.camera.name}] FFmpegError: {e}")
                self.need_restart = True
                self.capture_error = True
                time.sleep(3)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–∞—É–∑—É –¥–ª—è —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –æ—à–∏–±–æ–∫
            except Exception as e:
                Logger.err(f"‚ö†Ô∏è [{self.camera.name}] Unexpected error: {e}")
                self.need_restart = True
                self.capture_error = True
                time.sleep(5)

        self.destroy_output_container()
        self.stop_input_container()
        Logger.warn(f'‚õîÔ∏è [{self.camera.name}] stop stream')

    def _perform_restart(self):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–ª–Ω—ã–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –ø–æ—Ç–æ–∫–∞"""
        Logger.debug(f"üîÑ [{self.camera.name}] Performing full restart...")
        try:
            self.destroy_output_container()
            self.stop_input_container()
            self.create_input_container()
            self.last_frame_time = time.time()  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–∞–π–º–µ—Ä –∫–∞–¥—Ä–æ–≤
        except Exception as e:
            Logger.err(f"‚ö†Ô∏è [{self.camera.name}] Restart failed: {e}")
        finally:
            self.need_restart = False
            self.last_restart_time = time.time()

    def get_no_signal_frame(self):
        try:
            frame = cv2.imread(os.path.abspath('static/images/no-signal.jpg'))
            frame = imutils.resize(frame, width=640)
        except Exception:
            frame = np.zeros((640, 360, 1), dtype="uint8")
        return frame

    def generate_frames(self):
        time_prev = 0
        fps = 15

        while True:
            if self.input_container is None or self.resized is None:
                frame = self.get_no_signal_frame()
            else:
                frame = self.resized

            time_elapsed = time.time() - time_prev
            time_prev = time.time()

            ret, buffer = cv2.imencode('.jpg', frame)
            if not ret:
                continue

            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + buffer.tobytes() + b'\r\n')

    def save_event(self):
        pass
